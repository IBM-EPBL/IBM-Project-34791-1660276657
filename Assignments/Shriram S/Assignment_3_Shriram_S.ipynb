{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vR4Wx5slOpGm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Convolution2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jf6Cwpk9RLwk"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/Flowers-Dataset/flowers/Train\"\n",
        "test_path = \"/content/Flowers-Dataset/flowers/Test\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Image Augmentation**"
      ],
      "metadata": {
        "id": "0zFMzkbBD8WC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFRDm1PhTNjV",
        "outputId": "d0c9089b-6f70-48c8-aa84-82dd16552ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers-Dataset/flowers/Train/daisy\n"
          ]
        }
      ],
      "source": [
        "x_train = []\n",
        "sub_path = train_path + \"/daisy\"\n",
        "print(sub_path)\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path = sub_path + \"/\" + img\n",
        "  img_arr = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_train.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwElT99CTY-N",
        "outputId": "a36b250b-d8d0-4f7f-8814-dc52e67bd42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers-Dataset/flowers/Train/dandelion\n"
          ]
        }
      ],
      "source": [
        "sub_path = train_path + \"/dandelion\"\n",
        "print(sub_path)\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path = sub_path + \"/\" + img\n",
        "  img_arr = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_train.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAqfYv0TTczV",
        "outputId": "94446e2a-78fd-47ba-b3bf-dcb72b1d2de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers-Dataset/flowers/Train/rose\n"
          ]
        }
      ],
      "source": [
        "sub_path = train_path + \"/rose\"\n",
        "print(sub_path)\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path = sub_path + \"/\" + img\n",
        "  img_arr = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_train.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-wpyMSSTeiV",
        "outputId": "6eebbdf3-16dd-44fc-9be3-f9bd38e61365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers-Dataset/flowers/Train/sunflower\n"
          ]
        }
      ],
      "source": [
        "sub_path = train_path + \"/sunflower\"\n",
        "print(sub_path)\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path = sub_path + \"/\" + img\n",
        "  img_arr = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_train.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4CufkYNTged",
        "outputId": "ddc4c99e-108e-404f-95f1-f9c498091e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Flowers-Dataset/flowers/Train/tulip\n"
          ]
        }
      ],
      "source": [
        "sub_path = train_path + \"/tulip\"\n",
        "print(sub_path)\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path = sub_path + \"/\" + img\n",
        "  img_arr = cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_train.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z80Ue8N8TmaN"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "sub_path=test_path+\"/daisy\"\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path=sub_path+\"/\"+img\n",
        "  img_arr=cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_test.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xwPwa5_MTrXu"
      },
      "outputs": [],
      "source": [
        "sub_path=test_path+\"/dandelion\"\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path=sub_path+\"/\"+img\n",
        "  img_arr=cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_test.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EfAhi5yzTuiG"
      },
      "outputs": [],
      "source": [
        "sub_path=test_path+\"/rose\"\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path=sub_path+\"/\"+img\n",
        "  img_arr=cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_test.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "522nOGoTTxcm"
      },
      "outputs": [],
      "source": [
        "sub_path=test_path+\"/sunflower\"\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path=sub_path+\"/\"+img\n",
        "  img_arr=cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_test.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wdTsBltmTy2t"
      },
      "outputs": [],
      "source": [
        "sub_path=test_path+\"/tulip\"\n",
        "for img in os.listdir(sub_path):\n",
        "  image_path=sub_path+\"/\"+img\n",
        "  img_arr=cv2.imread(image_path)\n",
        "  img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(224,224))\n",
        "  img = img.reshape(224,224,3)\n",
        "  x_test.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPQkEh2gT0bF",
        "outputId": "690ed473-dbc7-4c41-d5a6-e2deaff9935d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3192, 224, 224, 3)\n",
            "(1125, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "train_x = np.array(x_train)\n",
        "test_x = np.array(x_test)\n",
        "\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E5yqmwc_T2Ke"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP9NS6UhT3UP",
        "outputId": "0a23d52f-3d81-4a6c-a15a-04ce1fbcdaa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3192 images belonging to 5 classes.\n",
            "Found 1125 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uIqXPHPfT5OV"
      },
      "outputs": [],
      "source": [
        "train_y = training_set.classes\n",
        "test_y = test_set.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXuJzmoHUOJW",
        "outputId": "208f4601-9061-4e71-e838-c757d0c3f0b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "K-0XksS6UTk9"
      },
      "outputs": [],
      "source": [
        "classes = [\"daisy\",\"dandelion\",\"rose\",\"sunflower\",\"tulip\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l4ZcJyCdUU6n"
      },
      "outputs": [],
      "source": [
        "train_x=train_x/255.0\n",
        "test_x=test_x/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Create Model**"
      ],
      "metadata": {
        "id": "I-8AxyA5EJ3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c12530YpUXed"
      },
      "outputs": [],
      "source": [
        "#Building the CNN\n",
        "# Initializing the CNN\n",
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)**"
      ],
      "metadata": {
        "id": "APlAxOZXEzwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convolution layer and pooling\n",
        "classifier.add(Convolution2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Second convolution layer and pooling\n",
        "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flattening the layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dropout(0.40))\n",
        "classifier.add(Dense(units=96, activation='relu'))\n",
        "classifier.add(Dropout(0.40))\n",
        "classifier.add(Dense(units=64, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2"
      ],
      "metadata": {
        "id": "3jh2y6fZE6bi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **4. Compile The Model**"
      ],
      "metadata": {
        "id": "gSm3WfjRE5sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SGjnWEmIFBL6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kFlKoitUoNt",
        "outputId": "33f93983-003c-4274-df2e-cebf5a29f483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 93312)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11944064  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,973,125\n",
            "Trainable params: 11,973,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Fit The Model**"
      ],
      "metadata": {
        "id": "hgYO4gJnFEE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrVjBwwMUq21",
        "outputId": "48a7911b-8ad1-42e6-8fab-317f3d4ae50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 172s 2s/step - loss: 1.4816 - accuracy: 0.3506 - val_loss: 1.4133 - val_accuracy: 0.3422\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 177s 2s/step - loss: 1.2649 - accuracy: 0.4574 - val_loss: 1.1625 - val_accuracy: 0.4791\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 173s 2s/step - loss: 1.1021 - accuracy: 0.5467 - val_loss: 1.1519 - val_accuracy: 0.5538\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 176s 2s/step - loss: 0.8770 - accuracy: 0.6454 - val_loss: 1.1342 - val_accuracy: 0.5733\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 173s 2s/step - loss: 0.6691 - accuracy: 0.7378 - val_loss: 1.1589 - val_accuracy: 0.6142\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 173s 2s/step - loss: 0.4551 - accuracy: 0.8349 - val_loss: 1.5508 - val_accuracy: 0.6027\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 174s 2s/step - loss: 0.3381 - accuracy: 0.8819 - val_loss: 1.7510 - val_accuracy: 0.5867\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 175s 2s/step - loss: 0.2338 - accuracy: 0.9173 - val_loss: 1.7031 - val_accuracy: 0.6151\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 174s 2s/step - loss: 0.1846 - accuracy: 0.9455 - val_loss: 1.9242 - val_accuracy: 0.5858\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 173s 2s/step - loss: 0.1756 - accuracy: 0.9561 - val_loss: 1.7766 - val_accuracy: 0.5929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f216b117f50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "classifier.fit(train_x, train_y, epochs=10, validation_data=(test_x, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Save The Model**"
      ],
      "metadata": {
        "id": "ZzeiUgo3FJdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1b14gGv3ri28"
      },
      "outputs": [],
      "source": [
        "classifier.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la8wkW7Tu0ps",
        "outputId": "9de2b9af-3e07-43b6-dbad-66f2b9b3f982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 15s 405ms/step - loss: 1.7766 - accuracy: 0.5929\n"
          ]
        }
      ],
      "source": [
        "loss, acc = classifier.evaluate(test_x, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. SUCCESSFULLY PREDICTED DAISY IMAGE FROM TEST IMAGES (Test The Model)**"
      ],
      "metadata": {
        "id": "X7TOGWuXCJKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = \"/content/Flowers-Dataset/flowers/Test/daisy/1150395827_6f94a5c6e4_n.jpg\"\n",
        "\n",
        "test = []\n",
        "img_arr = cv2.imread(img)\n",
        "\n",
        "img1 = cv2.resize(img_arr,(224,224))\n",
        "img1 = img1.reshape(224,224,3)\n",
        "\n",
        "test.append(img1)\n",
        "test_img = np.array(test)\n",
        "test_img = test_img/255\n",
        "\n",
        "pred = classifier.predict(test_img)\n",
        "print(classes[np.argmax(pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRqMYVarB1qC",
        "outputId": "851096a6-331a-41b3-c18b-5e251e770f7b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "daisy\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}